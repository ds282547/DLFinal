# Polyphonic Piano Music Transcription
The final project of 2019 NCTU Deep Learning and Practice (Spring).

**Group Member:** Jennifer Wang, Hike Chen(ds282547)

# Introduction
Automatic Music Transcription (AMT) automates the process of converting an acoustic musical signal into some form of musical notation.
The AMT problem can be divided into several subtasks: multi-pitch detection, note onset/offset detection, quantization â€¦ etc.

We implemented a Hybrid-RNN proposed by [1] to convert piano audio into musical notation in midi format.

# Convert Result
[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)]

# Reference
[1] Sigtia, Siddharth, Emmanouil Benetos, and Simon Dixon. "An end-to-end neural network for polyphonic piano music transcription." IEEE/ACM Transactions on Audio, Speech, and Language Processing 24.5 (2016): 927-939.

[2] Boulanger-Lewandowski, Nicolas, Yoshua Bengio, and Pascal Vincent. "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription." arXiv preprint arXiv:1206.6392 (2012).

[3] Boulanger-Lewandowski, Nicolas, Yoshua Bengio, and Pascal Vincent. "High-dimensional sequence transduction." 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2013.
