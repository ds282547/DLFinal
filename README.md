# Polyphonic Piano Music Transcription
The final project of 2019 NCTU Deep Learning and Practice (Spring).

**Group Member:** Jennifer Wang, Hike Chen(ds282547)

# Introduction
Automatic Music Transcription (AMT) automates the process of converting an acoustic musical signal into some form of musical notation.
The AMT problem can be divided into several subtasks: multi-pitch detection, note onset/offset detection, quantization … etc.

We implemented a Hybrid model proposed by [1] to convert piano audio into musical notation in midi format. \
More details in [slides](https://github.com/ds282547/DLFinal/blob/main/slide/slide.pdf).

# Transcription Result Video

### Song1 :
### Song2 :

[Original](https://www.youtube.com/watch?v=FnzoMzA9Dpg) : ちょっとたのしい「千本桜（Senbonzakura）」 を弾いてみた【ピアノ】\
[Result](https://www.youtube.com/watch?v=FnzoMzA9Dpg)

# Reference
[1] Sigtia, Siddharth, Emmanouil Benetos, and Simon Dixon. "An end-to-end neural network for polyphonic piano music transcription." IEEE/ACM Transactions on Audio, Speech, and Language Processing 24.5 (2016): 927-939.
